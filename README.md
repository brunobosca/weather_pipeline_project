# ğŸŒ¦ï¸ Clima em Tempo Real com Python + AWS S3

Este projeto coleta dados meteorolÃ³gicos em tempo real utilizando a **API do OpenWeather**, transforma as informaÃ§Ãµes em `.CSV`, e envia os dados automaticamente para um **bucket no AWS S3**, formando uma mini-pipeline de dados moderna.

---

## ğŸ”§ Tecnologias Utilizadas

- ğŸ Python 3.10+
- â˜ï¸ AWS S3 (armazenamento na nuvem)
- ğŸ” IAM (controle de permissÃµes seguro)
- ğŸ“¦ Bibliotecas: `boto3`, `requests`, `pandas`, `python-dotenv`
- ğŸ”„ AutomaÃ§Ã£o com scripts reutilizÃ¡veis

---

## ğŸ“ˆ Objetivo

Criar uma estrutura simples, porÃ©m escalÃ¡vel, de **extraÃ§Ã£o de dados via API pÃºblica**, **processamento** local e **armazenamento em nuvem**, simulando o funcionamento de pipelines de dados reais em projetos profissionais.

---

## âš™ï¸ Como Funciona

1. **Consulta API** do OpenWeather com coordenadas definidas (lat/lon)
2. Extrai informaÃ§Ãµes como:
   - Temperatura
   - Umidade
   - CondiÃ§Ã£o do cÃ©u
   - Vento
3. Salva o resultado formatado em um arquivo `.csv`
4. Faz o **upload automÃ¡tico para o AWS S3** com seguranÃ§a
5. (Opcional) Listagem de arquivos no bucket

---

## ğŸ§ª Como Executar

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/brunobosca/clima-pipeline-s3.git
cd clima-pipeline-s3

### 2. Instale os requisitos 

pip install -r requirements.txt

### 3. Configure as variÃ¡veis de ambiente

Crie um arquivo .env com as seguintes chaves:

AWS_ACCESS_KEY_ID=SUAS_CREDENCIAIS
AWS_SECRET_ACCESS_KEY=SUAS_CREDENCIAIS
AWS_REGION=us-east-2

### 4. Execute a pipeline

python pipeline.py


## ğŸ“ Estrutura do Projeto

ğŸ“¦ clima-pipeline-s3
â”œâ”€â”€ .env                 # VariÃ¡veis sensÃ­veis (NÃƒO subir pro GitHub)
â”œâ”€â”€ pipeline.py          # Pipeline principal
â”œâ”€â”€ s3_upload.py         # MÃ³dulo de upload para o S3
â”œâ”€â”€ listar_s3.py         # Lista arquivos no bucket
â”œâ”€â”€ dados_clima.csv      # Arquivo gerado
â”œâ”€â”€ README.md            # Este arquivo
â””â”€â”€ requirements.txt     # DependÃªncias


## ğŸš€ Potenciais ExtensÃµes

Armazenamento contÃ­nuo com agendamento (cron/Lambda)

Upload particionado por data (YYYY/MM/DD/arquivo.csv)

ConexÃ£o com bancos como Redshift, Athena, BigQuery, etc.

VisualizaÃ§Ã£o com Power BI ou Looker Studio (via S3 ou API)


## ğŸ”’ SeguranÃ§a
Este projeto segue boas prÃ¡ticas de seguranÃ§a:

Uso de .env para variÃ¡veis sensÃ­veis

Acesso controlado via usuÃ¡rio IAM com polÃ­tica mÃ­nima

Nunca expÃµe chaves diretamente no cÃ³digo

## ğŸ’¼ Sobre Mim
ğŸ‘‹ Me chamo Bruno e este projeto Ã© parte do meu portfÃ³lio voltado para engenharia de dados, cloud e automaÃ§Ã£o de pipelines com Python.
Estou em constante evoluÃ§Ã£o e buscando oportunidades para aplicar essas habilidades em ambientes reais.

## ğŸ“² Contato
LinkedIn: linkedin.com/in/brunoboscaini

GitHub: github.com/brunobosca


